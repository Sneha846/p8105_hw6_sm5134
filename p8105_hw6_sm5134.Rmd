---
title: "p8105_hw6_sm5134"
author: "Sneha Mehta"
date: "2022-11-29"
output: github_document
---

```{r setup, message=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(modelr)
library(mgcv)
```

## Problem 1

```{r, message=FALSE}
set.seed(1)

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

# Distribution of hat{r}^2
weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

The $\hat{r}^2$ value is quite high, clustered around ~0.915. The distribution appears fairly symmetric and we could take the 2.5% and 97.5% quantiles of the estimates to construct a confidence interval.


```{r}
# Distribution of log(\beta_0 * \beta1)
set.seed(1)
weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```
The distribution of $\log(\beta_0 * \beta1)$ is also fairly symmetric.


## Problem 2
```{r}
# Prep dataset
homicide = read_csv("./homicide-data.csv") %>% 
  janitor::clean_names() %>%
  mutate(city_state = str_c(city, state, sep = ", "),
         solved = if_else(disposition == "Closed by arrest",TRUE, FALSE)) %>% 
  filter(!(city_state == "Tulsa, AL" | city_state == "Dallas, TX" | city_state == "Phoenix, AZ" | city_state == "Kansas City, MO")) %>% 
  mutate(victim_age = as.numeric(victim_age)) %>% 
  filter(victim_race == "White" | victim_race == "Black")

# Creating dataset for Baltimore
baltimore = homicide %>% 
  filter(city == "Baltimore")

# Fitting logistic regression
fit_baltimore = 
  baltimore %>% 
  glm(solved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) 

# Cleaning fit
fit_baltimore = fit_baltimore %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         ci_lower = exp(estimate - 1.96*std.error),
         ci_upper = exp(estimate + 1.96*std.error))

# Tabulating Results
fit_baltimore %>% 
  select(term, OR, ci_lower,ci_upper, p.value) %>% 
  knitr::kable(digits = 3)
```
The odds of solving the homicide of a male victim is 0.426 times the odds of solving the homicide of a female victim, adjusting for age and race.

```{r, warning=FALSE}
full_glm = homicide %>% 
  nest(data = -city_state) %>% 
  mutate(models = map(data, ~glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())),
                       results = map(models, broom::tidy,conf.int = TRUE)) %>% 
  select(city_state, results) %>% 
  unnest(cols = results) %>% 
  mutate(OR = exp(estimate),
         ci_lower = exp(conf.low),
         ci_upper = exp(conf.high)) %>% 
  select(city_state, term, OR, ci_lower, ci_upper)

# Creating Plot
full_glm %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR, color = city_state)) +
  geom_point() +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper)) +
  labs(
    x = "City, State",
    y = "OR",
    title = "Odds of Solving Homicide by City") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme(legend.position = "none")
```

From the plot we can see that the city with the lowest odds of solving the homicide of a male versus a female is New York, NY and the highest is Albuquerque, NM. Only four cities have ORs over 1: Nashville,TN; Fresno, CA; Stockton,CA; and Albuquerque, NM. However, all of these cities have the null value of 1 within the 95% confidence interval so we cannot say that the OR is statistically significant.


## Problem 3
```{r}
# Prep dataset
birthweight = read_csv("./birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(babysex = as.factor(if_else(babysex==1, "male", "female")),
         mrace = as.factor(case_when(mrace == 1 ~ "White",
                           mrace == 2 ~ "Black",
                           mrace == 3 ~ "Asian",
                           mrace == 4 ~ "Puerto Rican",
                           mrace == 8 ~ "Other")),
         malform = as.factor(if_else(malform == 0, "absent", "present")))
```
The variables I selected for my model are `gaweeks`, `malform`, `mrace`, and `fincome`. I chose these variables based on my hypothesized factors that would have the greatest influence on birthweight while avoiding colinearity amongst the variables.

```{r}
# Model 1
fitweight1 = birthweight %>% 
  lm(bwt ~ gaweeks + malform + mrace + fincome, data = .)

birthweight %>% 
  add_predictions(fitweight1) %>% 
  add_residuals(fitweight1) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_violin()

# Model 2
fitweight2 = birthweight %>% 
  lm(bwt ~ gaweeks + blength, data = .)

# Model 3
fitweight3 = birthweight %>% 
  lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .)

# Computing root mean squared errors (RMSEs) for each model
rmse(fitweight1, birthweight) # 451.679
rmse(fitweight2, birthweight) # 333.102
rmse(fitweight3, birthweight) # 287.249

set.seed(1)
cv_bw = crossv_mc(birthweight, 100)

cv_bw =
  cv_bw %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_bw = cv_bw %>%
  mutate(fit1 = map(train, ~lm(bwt ~ gaweeks + malform + mrace + fincome, data = .x)),
         fit2 = map(train, ~lm(bwt ~ gaweeks + blength, data = .x)),
         fit3 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse1 = map2_dbl(fit1, test, ~rmse(model = .x, data = .y)),
         rmse2 = map2_dbl(fit2, test, ~rmse(model = .x, data = .y)),
         rmse3 = map2_dbl(fit3, test, ~rmse(model = .x, data = .y)))
# Plot
cv_bw %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
Based on the RMSE values displayed in the plot, Model 3 has the best fit of the three models since it has the lowest RMSE (mean value around 287). Model 1 was the worst fit of the three with the highest RMSE (mean value around 453).



